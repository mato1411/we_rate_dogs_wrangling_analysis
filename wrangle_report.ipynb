{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03361e89",
   "metadata": {},
   "source": [
    "# Data Wrangling Report\n",
    "\n",
    "## Introduction\n",
    "This project was submitted as part of Udacity's Data Analyst Nanodegree program. Within this notebook data wrangling techniques are used to obtain data that is analyzed and visualized. The project motivation is to gain insights about the top dog breeds rated by [WeRateDogs](https://twitter.com/dog_rates9). This document briefly describes the data wrangling efforts.\n",
    "\n",
    "## Gathering Data\n",
    "The data will be gathered from 3 different data sources:\n",
    "1. The WeRateDogs Twitter archive `data/twitter-archive-enhanced.csv` has been provided by Udacity. The file will be loaded into a dedicated DataFrame called `df_archive` using pandas.\n",
    "1. The file `data/image_predictions.tsv` is hosted on Udacity's servers and will be downloaded programmatically using the Requests library. It contains the tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. The file will be loaded into a dedicated DataFrame called `df_img` using pandas.\n",
    "1. Using the tweet IDs in the WeRateDogs Twitter archive, the Twitter API for each tweet's JSON data using Python's Tweepy library was queried. Each tweet's entire set of JSON data will be stored i a file called `data/tweet_json.txt file`. Each tweet's JSON data is stored to its own line. The tweet ID, retweet count, and favorite count will be loaded from this file into a dedicated DataFrame called `df_api` using pandas. To avoid exposing the Twitter developer accounts credentials used for accessing the Twitter API, the API Key was set as environment vairable `CONSUMER_KEY` and the secret as environment vairable `CONSUMER_SECRET`.\n",
    "\n",
    "## Assessing Data\n",
    "After gathering each of the above pieces of data, the data will be visually and programmatically assessed for quality and tidiness issues. The columns of each DataFrame will be described. The detected issues will be documented. Only issues that help to satisfy the project motivation will be covered.\n",
    "\n",
    "**Following observations were made:**\n",
    "* There are no relevant duplicates, no dropping of duplicates required.\n",
    "* The column names are descriptive and do not include blanks. \n",
    "\n",
    "### Column description table `df_archive`\n",
    "* `tweet_id` is the last part of the tweet URL after \"status/\", e.g. https://twitter.com/dog_rates/status/892420643555336193/\n",
    "* `in_reply_to_status_id` will contain the integer representation of the original Tweet’s ID, if the represented Tweet is a reply\n",
    "* `in_reply_to_user_id` will contain the integer representation of the original Tweet’s author ID, if the represented Tweet is a reply\n",
    "* `timestamp` is the UTC time when this Tweet was created\n",
    "* `source` is the Utility used to post the Tweet, as an HTML-formatted string\n",
    "* `text` is the actual UTF-8 text of the status update\n",
    "* `retweeted_status_id` will contain the integer representation of the original Tweet’s ID, if the represented Tweet is a retweet\n",
    "* `retweeted_status_user_id` will contain the integer representation of the original Tweet’s author ID, if the represented Tweet is a retweet\n",
    "* `retweeted_status_timestamp` will contain the UTC time when the original Tweet was created, if the represented Tweet is a retweet\n",
    "* `expanded_urls` expanded version of the URL pasted/typed into Tweet\n",
    "* `rating_numerator` the rating numerator defining the rating of the specifc dog associated with this tweet\n",
    "* `rating_denominator` the rating denominator defining the rating of the specifc dog associated with this tweet\n",
    "* `name` the name of the specifc dog associated with this tweet\n",
    "* `doggo` is a dog stage\n",
    "* `floofer` is a dog stage\n",
    "* `pupper` is a dog stage\n",
    "* `puppo` is a dog stage\n",
    "\n",
    "### Column description table `df_img`\n",
    "* `tweet_id` is the last part of the tweet URL after \"status/\", e.g. https://twitter.com/dog_rates/status/892420643555336193/\n",
    "* `jpg_url` is the URL to the image\n",
    "* `img_num` is the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images)\n",
    "* `p1` is the algorithm's #1 prediction for the image in the tweet\n",
    "* `p1_conf` is how confident the algorithm is in its #1 prediction\n",
    "* `p1_dog` is whether or not the #1 prediction is a breed of dog\n",
    "* `p2` is the algorithm's second most likely prediction\n",
    "* `p2_conf` is how confident the algorithm is in its #2 prediction\n",
    "* `p2_dog` is whether or not the #2 prediction is a breed of dog\n",
    "* `p3` is the algorithm's second most likely prediction\n",
    "* `p3_conf` is how confident the algorithm is in its #2 prediction\n",
    "* `p3_dog` is whether or not the #2 prediction is a breed of dog\n",
    "\n",
    "### Column description table `df_api`\n",
    "\n",
    "* `id` is the last part of the tweet URL after \"status/\", e.g. https://twitter.com/dog_rates/status/892420643555336193/\n",
    "* `favorite_count` indicates approximately how many times this Tweet has been liked by Twitter users\n",
    "* `retweet_count` is the number of times the tweet has been retweeted\n",
    "\n",
    "<a id='a-quality'></a>\n",
    "### Quality Issues\n",
    "\n",
    "#### `df_archive` table\n",
    "* Some tweets are retweets and should be dropped, because they might be no original ratings\n",
    "* Some tweets are replies and should be dropped, because they might be no original ratings (additionally, the columns `in_reply_to_status_id` and `in_reply_to_user_id` are `float64` instead of `int64` but this extraneous)\n",
    "* The rating is sometimes incorrect by comparing text to `rating_numerator` and `rating_denominator` outliers\n",
    "* The rating needs to be normalized by `rating_numerator` divided by `rating_denominator` due to the outliers\n",
    "* The columns `name`, `doggo`, `floofer`, `pupper` and `puppo` contain the string `None` instead of `np.nan` as null value\n",
    "* The column `name` contains very likely not real names, i.e. `a`, `by`, `unacceptable`, `very`, `an`, `my` and `incredibly`.\n",
    "* The `timestamp` and `retweeted_status_timestamp` is represented as string and should be a datetime value (only `timestamp` requires cleaning, because retweets will not be considered)\n",
    "\n",
    "#### `df_img` table\n",
    "* If a dog was detected, then get the dog breed based on the highest confidence prediction\n",
    "* The confidence of some predicted dog breeds is below 30%\n",
    "* The predicted dog breed consisting of more than one word for p1 or p2 or p3 are separated by `_` or `-` instead of blank. Additionally, the words sometimes do not start capitalized \n",
    "\n",
    "#### `df_api` table\n",
    "* No issues identified\n",
    "\n",
    "<a id='a-tidiness'></a>\n",
    "### Tidiness Issues\n",
    "* In table `df_archive` each dog stage has it's own column (`doggo`, `floofer`, `pupper` and `puppo`), which will be changed to a single column `dog_stage`\n",
    "* The table `df_archive` has tweets that are not represented in the table `df_img` and `df_api`\n",
    "* The table `df_img` should be part of the `df_archive` table\n",
    "* The table `df_api` should be part of the `df_archive` table\n",
    "\n",
    "## Cleaning Data\n",
    "There were no missing data issues to be cleaned first. That's why tidiness issues were cleaned first. Finally, quality issues were cleaned. The results of cleaning will be a high quality and tidy master pandas DataFrame `df_archive_clean` that is required to satisfy the Project Motivation. For each issue the cleaning process is structures by define, code, and test steps which are documented.\n",
    "\n",
    "The results of cleaning is a high quality and tidy master pandas DataFrame `df_archive_clean` that is required to satisfy the Project Motivation. This master DataFrame will be saved as `data/twitter_archive_master.csv` using pandas. The DataFrame `df_api_cleaned` will be additionally to the file `data/tweet_json.txt` produced by querying Twitter's API stored as CSV file `data/twitter_api_cleaned.csv`. It's not required for further analysis, because the data was merged to the master DataFrame. Still, the CSV file makes it easier to access this data compared to the original produced txt-file. The DataFrame `df_img_clean` was not stored as CSV, because the data was merged to the master DataFrame.\n",
    "\n",
    "The wrangled data provided within the master DataFrame `df_archive_clean` will be analyzed to produce insights and visualizations that satisfy the project motivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b912d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
